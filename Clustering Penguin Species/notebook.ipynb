{"cells":[{"source":"![Alt text](https://imgur.com/orZWHly.png=80)\nsource: @allison_horst https://github.com/allisonhorst/penguins","metadata":{},"id":"589fe37e-e764-4d71-9c3c-93c8b7acee79","cell_type":"markdown"},{"source":"You have been asked to support a team of researchers who have been collecting data about penguins in Antartica! The data is available in csv-Format as `penguins.csv`\n\n**Origin of this data** : Data were collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network.\n\n**The dataset consists of 5 columns.**\n\nColumn | Description\n--- | ---\nculmen_length_mm | culmen length (mm)\nculmen_depth_mm | culmen depth (mm)\nflipper_length_mm | flipper length (mm)\nbody_mass_g | body mass (g)\nsex | penguin sex\n\nUnfortunately, they have not been able to record the species of penguin, but they know that there are **at least three** species that are native to the region: **Adelie**, **Chinstrap**, and **Gentoo**.  Your task is to apply your data science skills to help them identify groups in the dataset!","metadata":{},"id":"d3fb84f2-0eda-4b73-95c0-5364f83e25bf","cell_type":"markdown"},{"source":"# Import Required Packages\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\n# Loading and examining the dataset\npenguins_df = pd.read_csv(\"penguins.csv\")\npenguins_df.head()\n","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1720536972279,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import Required Packages\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\n# Loading and examining the dataset\npenguins_df = pd.read_csv(\"penguins.csv\")\npenguins_df.head()\n","lastExecutedByKernel":"241fffed-d3c0-45d4-9774-ca6129fa5f86","outputsMetadata":{"0":{"height":195,"type":"dataFrame"}}},"id":"57295d13-5753-4f8d-aa96-cd6815f7cbd9","cell_type":"code","execution_count":22,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"culmen_length_mm","type":"number"},{"name":"culmen_depth_mm","type":"number"},{"name":"flipper_length_mm","type":"number"},{"name":"body_mass_g","type":"number"},{"name":"sex","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4],"culmen_length_mm":[39.1,39.5,40.3,36.7,39.3],"culmen_depth_mm":[18.7,17.4,18,19.3,20.6],"flipper_length_mm":[181,186,195,193,190],"body_mass_g":[3750,3800,3250,3450,3650],"sex":["MALE","FEMALE","FEMALE","FEMALE","MALE"]}},"total_rows":5,"truncation_type":null},"text/plain":"   culmen_length_mm  culmen_depth_mm  flipper_length_mm  body_mass_g     sex\n0              39.1             18.7              181.0       3750.0    MALE\n1              39.5             17.4              186.0       3800.0  FEMALE\n2              40.3             18.0              195.0       3250.0  FEMALE\n3              36.7             19.3              193.0       3450.0  FEMALE\n4              39.3             20.6              190.0       3650.0    MALE","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>culmen_length_mm</th>\n      <th>culmen_depth_mm</th>\n      <th>flipper_length_mm</th>\n      <th>body_mass_g</th>\n      <th>sex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39.1</td>\n      <td>18.7</td>\n      <td>181.0</td>\n      <td>3750.0</td>\n      <td>MALE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>39.5</td>\n      <td>17.4</td>\n      <td>186.0</td>\n      <td>3800.0</td>\n      <td>FEMALE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>40.3</td>\n      <td>18.0</td>\n      <td>195.0</td>\n      <td>3250.0</td>\n      <td>FEMALE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>36.7</td>\n      <td>19.3</td>\n      <td>193.0</td>\n      <td>3450.0</td>\n      <td>FEMALE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>39.3</td>\n      <td>20.6</td>\n      <td>190.0</td>\n      <td>3650.0</td>\n      <td>MALE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":22}]},{"source":"# Separate numeric and categorical columns\nnum_features = penguins_df.select_dtypes(include=['float64', 'int64']).columns\ncategorical_features = penguins_df.select_dtypes(include=['object']).columns\n\n# Preprocess using ColumnTransformer for scaling and encoding\nnum_scaler = StandardScaler()\ncat_scaler = OneHotEncoder(drop= 'first')\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', num_scaler, num_features),\n        ('cat', cat_scaler, categorical_features)\n    ])\n\n# Fit and transform the data\ntransformed_features = preprocessor.fit_transform(penguins_df)","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1720536972331,"lastExecutedByKernel":"241fffed-d3c0-45d4-9774-ca6129fa5f86","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Separate numeric and categorical columns\nnum_features = penguins_df.select_dtypes(include=['float64', 'int64']).columns\ncategorical_features = penguins_df.select_dtypes(include=['object']).columns\n\n# Preprocess using ColumnTransformer for scaling and encoding\nnum_scaler = StandardScaler()\ncat_scaler = OneHotEncoder(drop= 'first')\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', num_scaler, num_features),\n        ('cat', cat_scaler, categorical_features)\n    ])\n\n# Fit and transform the data\ntransformed_features = preprocessor.fit_transform(penguins_df)","outputsMetadata":{"0":{"height":196,"type":"dataFrame"}}},"cell_type":"code","id":"8db8f617-1416-452a-99ad-a2d0e1a5e4b0","outputs":[],"execution_count":23},{"source":"# Apply KMeans clustering\nk = 3  # Adjustable according to analysis\nkmeans = KMeans(n_clusters= k, random_state= 123)\npenguins_df['cluster'] = kmeans.fit_predict(transformed_features)\n\n# Calculate the mean values for each cluster\nstat_penguins = penguins_df.groupby('cluster').mean()\n\n# Display the DataFrame stat_penguins\nprint(stat_penguins)","metadata":{"executionCancelledAt":null,"executionTime":56,"lastExecutedAt":1720536972387,"lastExecutedByKernel":"241fffed-d3c0-45d4-9774-ca6129fa5f86","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Apply KMeans clustering\nk = 3  # Adjustable according to analysis\nkmeans = KMeans(n_clusters= k, random_state= 123)\npenguins_df['cluster'] = kmeans.fit_predict(transformed_features)\n\n# Calculate the mean values for each cluster\nstat_penguins = penguins_df.groupby('cluster').mean()\n\n# Display the DataFrame stat_penguins\nprint(stat_penguins)","outputsMetadata":{"0":{"height":122,"type":"stream"}}},"cell_type":"code","id":"ffc155e0-be1a-4f80-a504-6d6b52744162","outputs":[{"output_type":"stream","name":"stdout","text":"         culmen_length_mm  culmen_depth_mm  flipper_length_mm  body_mass_g\ncluster                                                                   \n0               47.477907        18.787209         197.279070  3918.604651\n1               38.356693        18.066929         188.244094  3571.259843\n2               47.568067        14.996639         217.235294  5092.436975\n"}],"execution_count":24}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}